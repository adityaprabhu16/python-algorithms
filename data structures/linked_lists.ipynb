{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linked Lists:\n",
    " - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy List with Random Pointer**:\n",
    " - This is a good copy a linked list problem, with an added twist of filling out the random pointer attribute for each Node. \n",
    " - We'll use a hash map to fill out the random pointer attribute. A hash map is useful here because we can refer to any node in the list as needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the Duplicate Number (in O(1) memory!)**\n",
    " - This is a great problem demonstrating Floyd's algorithm\n",
    " - We use the first half of this algorithm in problems such as Linked List Cycle, Delete Node from Linked List, Reverse Linked List from the Middle\n",
    " - Here we use the full algorithm!\n",
    "\n",
    " - How it works:\n",
    "  - We treat the values in the array as a pointer to the next index in the array.\n",
    "  - E.g. If we're at index 0, and the value nums[0] = 1, the next location our pointer will go to is pointer = nums[0] = 1, and so on.\n",
    "  - We'll have a fast pointer that goes fast = nums[nums[i]], where i is the current VALUE the pointer is on.\n",
    "  - We'll have a slow pointer that goes slow = nums[j]\n",
    "  - Both pointers start at index 0 (slow=fast=0)\n",
    "  - At the location these pointers meet after incrementing both, we've found a cycle\n",
    "  - We'll then introduce another slow pointer that starts at index 0, and the VALUE the first slow pointer and it meets at is our DUPLICATE!\n",
    "  - Why? You can draw this out, also see the general proof on Neetcode video. \n",
    "\n",
    "  Intuition:\n",
    "   - Essentially, since we're indexing into the array, if two pointers end up on the same index but they're going at different speeds, it means there was a cycle that lead them to that same index location, because eventually the two pointers would meet. That index that lead them to the same location must therefore be the duplicate in the array since they BOTH point to the same location in the array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##LRU Cache##\n",
    "- A really cool design problem where you'll understand a lot about datastructures.\n",
    "- We're essentially trying to maintain a cache in a similar manner that a browser might.\n",
    "- Specifically, we'll have a certain capacity. Whenever we get or put from the cache, we'll need to keep track of how often each item is used in the cache.\n",
    "- The datastructure we'll use is a doubly linked list and a hashMap, where each key in the map points to a node in the linked list. Rearranging the nodes won't impact the hashMap because it's only worried about pointing to the node, not where it is. \n",
    "- We'll create a new node class (make it OUTSIDE the existing class so we don't have to use self to call its methods)\n",
    "- We'll have 2 dummy nodes: lru and mru to denote the ends of the doubly linked list (most least recently used and most recently used respectively), like goal posts we'll build our linked list off of. Initially, they'll just be pointing to eachother. Initialize the key to float(\"-inf\") and float(\"+inf\") so they don't collidre with other keys. The values can just be 0.\n",
    "- We'll also include our own insert and remove methods. Whenever we put or get to our cache, we'll be using both of these methods to update the mru. We'll use remove to reassign the pointers of adjacent nodes so they bypass the node with the key we're trying to remove in normal linked list fashion.\n",
    "- We'll use insert to add a new key to the cache. We'll create a new node, insert it from the mru side because it would be the most recently used at that point, reassign the pointers of course, and then ensure our hashmap self.cache[key] = newNode. \n",
    "- To implement the given get method, we simply check if the key is in the cache. If it is, we'll save self.cache[key].val, do a remove(key), then insert(key, value) so the node is now on the MRU, and then we'll return self.cache[key].val. If the key doesn't exist in the cache, we'll return -1. \n",
    "- To implement the given put method, we'll check if the key is in the cache. If it is, we'll just do a remove and then an insert with the NEW value, similar to get. If it isn't, we'll just do an insert with the NEW value, and then check the capcity of the cache (len(cache)). If it's greater than the self.capacity we initialized the cache with, we'll do a remove(), but from the lru side (self.lru.next.key). This is why we initialized the lru and mru nodes. After we do the remove from the LRU side, we'll also have to PURGE that key-value (here the value is a node) pair from the hashmap, which we can do with the following SYNTAX:\n",
    " - del self.cache[key] "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
