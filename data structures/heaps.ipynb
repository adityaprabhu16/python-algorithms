{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heap Data Structure:\n",
    " - A complete binary tree that satisfies the heap property, sometimes referred to as a PRIORITY QUEUE. Not to be confused with MONOTONIC QUEUE (see sliding window maximum).\n",
    " - Complete Binary Tree: every level, except for the leaves, is completely filled & all of the nodes in the last level are filled from the left.\n",
    " - Heap Property: For every node, the value of its children is less than or equal to its own value (max heap) or vice versa (min heap)\n",
    "    - Therefore, the smallest or largest element will always be at the root of the tree.\n",
    "- Applications: Used for implementing a priority queue, and heapsort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heap Methods:\n",
    " - Heapify (building a max heap FROM SCRATCH): O(n)\n",
    " - Insert (Push) O(logN)\n",
    " - Delete        O(logN)\n",
    " - Pop Min / Max O(logN)\n",
    " - Peek O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why?\n",
    " - Insert, Delete, Pop may cause the heap to no longer have its heap property, so the tree needs to be repaired. Because the tree has already been built, worst case some nodes may need to be swapped all the way to the bottom, which would require O(logN) calls to our heapify proportional to the height of the tree.\n",
    " - Peek is O(1) because the root node, which will be the maximum or minimum value, will be at the front of the array and we can just access it via indexing.\n",
    " - Building the heap is O(n), which is counter-intuitive at first. We might think it should be proportional to O(NlogN) because we'll have to go through each node and it will take O(logN) worst-case to find its correct location. In reality, since we're building the heap from scratch, we're starting at floor(N/2) and working our way to index 0 in our array: note that floor(N/2 + 1) : N are all leaf nodes (roughly half of a complete binary tree will be leaf nodes). Since we build the tree at the first parents of the leaf nodes and working our way up, swaps for the MOST PART will be O(1) time. In other words, most nodes will not have to move much because they'll already be at the bottom of the tree and will be swapping between adjacent nodes. Only the very few nodes at the top of the tree might need O(logN) but the operation gets dominated by the lower nodes. Meanwhile, insert and delete are O(logN) because they generally impact the top of the tree which means nodes may have to be swapped all the way down to find its correct location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we implement Heapify, the operation behind insert / delete, and Build Max Heap?\n",
    " - Build max heap is called heapify in Python, which can cause some confusion. Think of build max heap as a wrapper to make multiple calls to heapify to correctly place each node in the right location as we traverse our array.\n",
    " - Note: for a given index, to access it's left and right child, left child will always be at 2*i if it exists, and the right child will be at 2*i + 1 if it exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: This is a max_heap example, for the min heap our bounds would be flipped.\n",
    "class Solution:\n",
    "    def build_max_heap(arr):\n",
    "        heap_size = len(arr)\n",
    "\n",
    "        for i in range(heap_size // 2, -1, -1):\n",
    "            max_heapify(arr, heap_size, i)\n",
    "    \n",
    "    def max_heapify(arr, heap_size, i):\n",
    "        l = 2*i\n",
    "        r = 2*i + 1\n",
    "        largest = i\n",
    "\n",
    "        #we're finding to see if any of the children are larger, and also to find the largest among them.\n",
    "        if l < heap_size and arr[l] > arr[i]:\n",
    "            largest = l\n",
    "        \n",
    "        if r < heap_size and arr[r] > arr[largest]:\n",
    "            largest = r\n",
    "        \n",
    "        if i != largest:\n",
    "            #swap i with the largest we found, and continue from where i is now located to repair that side of the heap.\n",
    "            arr[i], arr[largest] = arr[largest], arr[i]\n",
    "            max_heapify(arr, heap_size, largest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kth Largest Element in Array:\n",
    " - This will expose us to many different heap methods!\n",
    " - Strategy 1: Create min-heap (default in Python) of size N, pop first N-K elements to be left with k largest element\n",
    " - Strategy 2: Use the builtin heapq.nlargest to achieve the same result as strategy 1.\n",
    "\n",
    "Time Complexity for Strategies 1 and 2? O(nlogn + (n-k)logn + logn)\n",
    " - nlogn for n heappush operations (using heapify instead will be O(n) but this is for learning purposes)\n",
    " - (n-k)logn for n-k heappop operations\n",
    " - logn for last heappop to get kth element.\n",
    " - Overall O(nlogn) which is the slowest.\n",
    "\n",
    "Memory complexity O(n) because we have an n min-heap.\n",
    "\n",
    " - Strategy 3 (Best): to save memory, maintain a k min-heap and update it whenever we encounter an element bigger than the min, ensuring the heap will have the k biggest elements.\n",
    " - We'll use heapify to sort the first k elements, which will be O(k) time complexity because heapify operates building a tree from the ground up while the other operations repair an established tree from the top down which is more expensive.\n",
    " - We'll be using heapq.heapreplace in order to FIRST POP the min and then push our next element O(logk).\n",
    " \n",
    " Time Complexity: O(nlogk) - although we still go through n elements (technically (n-k) heap-wise, but n dominates here because k we'll generally assume to be smaller), our heap is smaller so less elements we have to traverse when repairing the heap.\n",
    " Memory Complexity: O(k) - only k elements in min-heap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strategy 1:\n",
    "class Solution:\n",
    "    def kthLargest(self, ums: List[int], k: int) -> int:\n",
    "        heap = []\n",
    "        for n in nums:\n",
    "            heapq.heappush(heap, n)\n",
    "        \n",
    "        for _ in range(len(nums)-k):\n",
    "            heapq.heappop(heap)\n",
    "        \n",
    "        return heapq.heapop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strategy 2:\n",
    "class Solution:\n",
    "    def kthLargest(self, nums: List[int], k: int) -> int:\n",
    "        #returns list of k largest elements, where last one will be smallest.\n",
    "        return heapq.nlargest(k, nums)[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strategy 3:\n",
    "class Solution:\n",
    "    def kthLargest(self, nums: List[int], k: int) -> int:\n",
    "        heap = nums[:k]\n",
    "\n",
    "        heapq.heapify(heap) #O(n) \n",
    "\n",
    "        for idx in range(k, len(nums)): #n-k elements:\n",
    "            #if greater than root (min), we'll replace the min with the greater to maintain heap of k greatest elements\n",
    "            if nums[idx] > heap[0]:\n",
    "                heapq.heapreplace(heap, nums[idx])  #O(logk)\n",
    "        \n",
    "        return heap[0] #top of heap will be min or kth largest element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Closest Points to Origin:\n",
    " - In this problem we're exposed to how we can pass in tuples into heaps for tagging and tracking purposes as the heap shifts our elements around.\n",
    " - In Python, the built in heap will only build the heap off of the first element in a tuple or array.\n",
    " - Generally use a tuple here because we don't want the data to change (immutable), so it's safer.\n",
    " - Here, we'll use heapq.heappushpop() which does the opposite of heapq.heapreplace: we first insert our element, allow the heap to repair, then pop the min.\n",
    " - Since we want the K smallest distances, we'll have to negate our distances when they go into the heap, so the root of the heap will be the smallest value but greatest absolute distance.\n",
    " - Time complexity will be O(nlogk) worst case (here we start with empty heap and either push or pushpop into it if we've already reached the max size we want the heap to be (k)) and memory will be O(k) again. \n",
    " - Note how we use some useful concepts like tuples, heap methods, list comprehension, enumerating objects, and destructuring in this problem to deliver a clean solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    def kClosestPoints(self, points: List[List[int]], k: int) -> List[List[int]]:\n",
    "        heap = []\n",
    "\n",
    "        for (x,y) in points:\n",
    "            dist = -1*(x*x + y*y)**0.5\n",
    "            #pushpop because heap full, maintain k closest points.\n",
    "            #we'll push a tuple to keep track of the x,y coordinates that gave us this distance, but only distance (first element) will be used to maintain the heap.\n",
    "            #only dist will be used in the comparisons. Since we're negative, the most negative (min) but absolute greatest distance will continue getting popped off until we have the k smallest distances (but greatest negatives)\n",
    "            if len(heap) == k:\n",
    "                heapq.heappushpop(heap, (dist, x, y)) #O(2logk), one for push, one for pop, but O(logk) simplified because constant time doesn't contribute to the overall complexity. \n",
    "            else:\n",
    "                heapq.heappush(heap, (dist, x, y)) #O(logk)\n",
    "        \n",
    "        #return the k closest (but greatest negative) points that we maintained in the heap.\n",
    "        return [(x,y) for (dist,x,y) in heap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top K Frequent Elements:\n",
    " - We're interested in grabbing the K most frequent elements from an array, where K is passed in dynamically.\n",
    " - To solve via heaps, we'll still use a hashMap to aggregate frequencies for each number O(n)\n",
    " - There's a useful collection methods called collections.Counter that can do this for us in one line to obtain {1: freq1, 2: freq2, ...}\n",
    " - We'll store the frequencies in an array of tuples (freq, n) [(freq1, 1), (freq2, 2), ...]\n",
    "   - Why not negate? Since we want the top K frequent elements and the heap is a min-heap by default, we'll need to know what the true min the heap currently is so we can replace it if something bigger comes along. In other words, a min heap is good for aggregating the biggest elements since our comparison (entrypoint) will be at the root which will always be the minimum, so we can replace it if we find something bigger, ensuring we'll only have the biggest.\n",
    " - We'll then grab the first k tuples and build a hashmap using the first element in the tuple freq O(k)\n",
    " - Keeping the heap the minimum size it needs to be (size k) is important because it will reduce time complexity when we do operations on the heap since the height of the heap will be smaller and traversal will be less expensive.\n",
    " - Go through the remainder of the tuples and update the heap so we're storing the K most frequent elements in it.\n",
    " - Use list comprehension to grab all of the numbers on the heap and return them.\n",
    "\n",
    " - Time complexity: O(nlogk) because worst case the frequencies happen to be sorted, so we'll be performing O(logk) for each frequency (n) we have to go through. However, this is better than O(nlogn) which would've been the case if we made a heap of n elements.\n",
    " - Memory complexity: O(k + 2n): O(k) for the heap and O(n) for the tuples worst case, assuming each number in the array is unique, therefore the frequencies array will be the same length as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    def topKFrequentElements(self, nums: List[int], k: int) -> List[int]:\n",
    "        freqMap = collections.Counter(nums)\n",
    "        freqTuples = []\n",
    "        for num, freq in freqMap.items():\n",
    "            freqTuples.append((freq, num))\n",
    "        \n",
    "        heap = freqTuples[:k]\n",
    "        heapq.heapify(heap) #O(k)\n",
    "\n",
    "        for i in range(k, len(freqTuples)):\n",
    "            tup = freqTuples[i]\n",
    "\n",
    "            #we found something bigger than the smallest currently in the heap, replace because we want the K biggest!\n",
    "            if tup[0] > heap[0][0]:\n",
    "                #Pop, then push\n",
    "                heapq.heapreplace(heap, tup)  #O(logk), we do it (n-k)logk times\n",
    "        \n",
    "        #now that heap as our k biggest elements:\n",
    "        return [h[1] for h in heap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task Scheduler\n",
    " - A great and interesting problem that shows you how tasks might get organized and processed by a real Operating System (OS) Scheduler.\n",
    " - Whenever a task of the same kind is processed, we are given that the task has a visibility timeout of n until it can be processed again.\n",
    " - If there are no tasks we can schedule at a given moment, this will result in idle time, increasing the time it takes to process the full batch (slower CPU)\n",
    " - We process one task per clock interval (recall the clock synchronizes the CPU) - you may have heard of overclocking used to describe strategies to reduce the clock interval to increase CPU efficiency. Usually however, the clock interval is generally the minimum time needed to process the slowest task or instruction, ensuring all other instructions can be processed within that time. Reducing it further may have unintended consequences such as some instructions not completing before the CPU moves to the next one. However, if such instructions are rare, overclocking can greatly reduce processing time, improving performance.\n",
    " - Given an array of tasks with possibly many of the same, we're asked to process them efficiently within a minimum number of clock intervals.\n",
    "\n",
    "Strategy:\n",
    " - Greedy algorithm essentially: it's always in our best interest to proces the most frequent tasks first if possible so we aren't left with the overhead of processing them with idle time later if we don't prioritize them.\n",
    " - By prioritizing scheduling for the most frequent tasks, we ensure we reduce idle time as much as possible by fitting in between other tasks while there is a timeout on that task.\n",
    " - Hence, we'll use a max-heap (-1*freq) to have the most frequent tasks at at the top, and a queue to store (freq, timeout) until a task is ready to be on the heap again.\n",
    " - Use collections.Counter to gather the frequencies of each task (remember Counter works on characters too)\n",
    " - Go through the frequencies and drop them in a heap.\n",
    " - While both the heap and the queue aren't empty, we'll try to reheapify first if there's any tasks ready from the queue to be placed in the heap again, followed by popping off the most frequent current task on the heap to prioritize it. Keep track of each iteration (clock interval)\n",
    " - We'll then reduce the frequency by 1 since we've processed one more of that task, compute the timeout = clock_interval + n + 1 (add 1 so we wait n callouts correctly) and place to the back of the queue.\n",
    " - Return that clock_interval which should now be the minimum.\n",
    " - NOTE: knowing the actual task isn't important in this problem as long as we have the frequencies. \n",
    "\n",
    " - Time complexity: O(nlogn): heap of n potential tasks if they all are unique. We'll have to do heappop an order of O(logn) times to schedule them, for total O(nlogn)\n",
    " - Memory complexity: O(n) for the heap of n elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution:\n",
    "    def TaskScheduler(self, tasks: List[str], n: int) -> int:\n",
    "        q = collections.deque()\n",
    "        freqMap = collections.Counter(tasks)\n",
    "\n",
    "        heap = []\n",
    "        for num, freq in freqMap.items():\n",
    "            heap.append(-1*freq)\n",
    "        \n",
    "        heapq.heapify(heap) #O(n)\n",
    "\n",
    "        clock_interval = 0\n",
    "\n",
    "        while heap or q:\n",
    "            if q:\n",
    "                #if the timeout is now less than clock_interval, (our curren time has exceeded the timeout) it's ready to go back in heap!\n",
    "                if clock_interval >= q[0][1]:\n",
    "                    tup = q.popleft()\n",
    "                    heapq.heappush(heap, tup[0])\n",
    "                \n",
    "            if heap:\n",
    "                freq = heapq.heappop(heap)\n",
    "                #remember: freq here is negative so maintain a max heap.\n",
    "                freq += 1\n",
    "                #if freq == 0  now, we have no more of this task to process, so don't put it in the queue!\n",
    "                if freq != 0:\n",
    "                    timeout = clock_interval + n + 1\n",
    "                    q.append((freq, timeout))\n",
    "            \n",
    "            clock_interval += 1\n",
    "        return clock_interval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
